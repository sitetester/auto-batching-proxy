use clap::Parser;
use rocket::log::LogLevel;
use serde::{Deserialize, Serialize};
use std::time::Duration;
use tokio::time::Interval;

#[derive(Parser, Debug, Default)]
#[command(author, version, about, long_about = None)]
pub struct Args {
    /// Rocket server port to run the proxy on
    #[arg(long)]
    pub port: Option<u16>,

    /// Maximal time user request can wait for other requests to be accumulated in a batch
    #[arg(long)]
    pub max_wait_time_ms: Option<u64>,

    /// Maximal number of requests that can be accumulated in a batch
    #[arg(long)]
    pub max_batch_size: Option<usize>,

    /// How often it can apply pending requests age check
    /// Smaller value will cause unnecessary CPU load, higher will cause poor API response
    #[arg(long)]
    pub batch_check_interval_ms: Option<u64>,

    /// Whether to include batching info in response. Helpful in development. Used in tests.
    #[arg(long)]
    pub include_batch_info: Option<bool>,

    /// Inference service full URL
    #[arg(long)]
    pub inference_url: Option<String>,

    /// Inference service timeout
    #[arg(long)]
    pub inference_timeout_secs: Option<u64>,

    /// Max inputs per call, which inference service can accept, each have own settings,
    /// e.g., `--model-id sentence-transformers/all-MiniLM-L6-v2` handles max 32 inputs
    #[arg(long)]
    pub max_inference_inputs: Option<usize>,

    /// For Application logging
    #[arg(long)]
    pub log_level: Option<LogLevel>,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct AppConfig {
    pub port: u16,
    pub max_wait_time_ms: u64,
    pub max_batch_size: usize,
    pub batch_check_interval_ms: u64,
    pub include_batch_info: bool,
    pub inference_url: String,
    pub inference_timeout_secs: u64,
    pub max_inference_inputs: usize,
    pub log_level: String,
    /// This is used in `Timing Summary` analysis test, because we want to suppress all type of warnings
    /// generated by Rocket to optimize performance (Too many logging calls are expensive :))
    pub quiet_mode: bool,
}

impl Default for AppConfig {
    fn default() -> Self {
        Self {
            port: 3000,
            max_wait_time_ms: 500,
            max_batch_size: 8,
            batch_check_interval_ms: 10, // in general, 100 ms is good enough
            include_batch_info: false,
            inference_url: "http://127.0.0.1:8080/embed".to_string(),
            inference_timeout_secs: 30,
            max_inference_inputs: 32,
            log_level: "info".to_string(),
            quiet_mode: false,
        }
    }
}

impl AppConfig {
    /// Build config from CLI args and defaults
    pub fn build(args: Option<Args>) -> Result<Self, String> {
        let mut config = Self::default();
        if let Some(args) = args {
            if let Some(port) = args.port {
                config.port = port;
            }

            if let Some(max_wait_time_ms) = args.max_wait_time_ms {
                if max_wait_time_ms == 0 {
                    return Err("max_wait_time_ms must be > 0".to_string());
                }
                config.max_wait_time_ms = max_wait_time_ms;
            }

            if let Some(max_batch_size) = args.max_batch_size {
                if max_batch_size == 0 {
                    return Err("max_batch_size must be > 0".to_string());
                }
                config.max_batch_size = max_batch_size;
            }

            if let Some(batch_check_interval_ms) = args.batch_check_interval_ms {
                if batch_check_interval_ms == 0 {
                    return Err("batch_check_interval_ms must be > 0".to_string());
                }
                config.batch_check_interval_ms = batch_check_interval_ms;
            }

            if let Some(include_batch_info) = args.include_batch_info {
                config.include_batch_info = include_batch_info;
            }

            if let Some(inference_url) = args.inference_url {
                config.inference_url = inference_url;
            }

            if let Some(inference_timeout_secs) = args.inference_timeout_secs {
                if inference_timeout_secs == 0 {
                    return Err("inference_timeout_secs must be > 0".to_string());
                }
                config.inference_timeout_secs = inference_timeout_secs;
            }

            // max 32 check is not applied here, since each model have own configs
            if let Some(max_inference_inputs) = args.max_inference_inputs {
                if max_inference_inputs == 0 {
                    return Err("max_inference_inputs must be > 0".to_string());
                }
                config.max_inference_inputs = max_inference_inputs;
            }

            if let Some(log_level) = args.log_level {
                config.log_level = log_level.to_string().to_lowercase();
            }
        }
        Ok(config)
    }

    pub fn max_wait_time_duration(&self) -> Duration {
        Duration::from_millis(self.max_wait_time_ms)
    }

    pub fn get_batch_interval(&self) -> Interval {
        tokio::time::interval(Duration::from_millis(self.batch_check_interval_ms))
    }

    /// Initialize logging with env_logger (simpler approach)
    pub fn init_logging(&self) -> String {
        env_logger::Builder::from_env(
            env_logger::Env::default().default_filter_or(&self.log_level),
        )
        .init();
        std::env::var("RUST_LOG").unwrap_or_else(|_| self.log_level.clone())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_build_from_default() {
        let config = AppConfig::build(None);
        assert!(config.is_ok());
        let config = config.unwrap();

        let defaults = AppConfig::default();
        assert_eq!(config.port, defaults.port);
        assert_eq!(config.max_wait_time_ms, defaults.max_wait_time_ms);
        assert_eq!(config.max_batch_size, defaults.max_batch_size);
        assert_eq!(
            config.batch_check_interval_ms,
            defaults.batch_check_interval_ms
        );
        assert_eq!(config.inference_url, defaults.inference_url);
        assert_eq!(
            config.inference_timeout_secs,
            defaults.inference_timeout_secs
        );
        assert_eq!(config.log_level, defaults.log_level);
    }

    #[test]
    fn test_build_from_args() {
        let args = Args {
            port: Some(6000),
            max_wait_time_ms: Some(200),
            max_batch_size: Some(16),
            batch_check_interval_ms: Some(50),
            include_batch_info: Some(false),
            inference_url: Some("http://custom:9090/embed".to_string()),
            inference_timeout_secs: Some(60),
            max_inference_inputs: Some(16),
            log_level: Some(LogLevel::Debug),
        };

        let config = AppConfig::build(Some(args));
        assert!(config.is_ok());
        let config = config.unwrap();

        assert_eq!(config.port, 6000);
        assert_eq!(config.max_wait_time_ms, 200);
        assert_eq!(config.max_batch_size, 16);
        assert_eq!(config.batch_check_interval_ms, 50);
        assert!(!config.include_batch_info);
        assert_eq!(config.inference_url, "http://custom:9090/embed");
        assert_eq!(config.inference_timeout_secs, 60);
        assert_eq!(config.max_inference_inputs, 16);
        assert_eq!(config.log_level, "debug".to_string());
    }

    #[test]
    fn test_build_from_partial_args() {
        let partial_args = Args {
            port: Some(5000),
            max_batch_size: Some(25),
            ..Args::default()
        };

        let config = AppConfig::build(Some(partial_args));
        assert!(config.is_ok());
        let config = config.unwrap();

        let defaults = AppConfig::default();
        assert_eq!(config.port, 5000);
        assert_eq!(config.max_batch_size, 25);
        // a few other checks
        assert_eq!(config.max_wait_time_ms, defaults.max_wait_time_ms);
        assert_eq!(config.inference_url, defaults.inference_url);
    }

    #[test]
    fn test_build_fails_when_values_are_zero() {
        macro_rules! test_zero_fields {
            // `[]` Outer parentheses - defines the input signature, args must match "this" ([]) syntax
            [
                // `$( ... )*` Repetition Group - everything inside is the repeating unit, multiple elements that repeat together
                $(
                    // `$field` - Metavariable - captures each input token (any valid identifier)
                    // `:ident` - Fragment Specifier - Specifies what type of token to expect
                    $field:ident
                )
                // `,` - Fields separator
                // `*`- Repetition Quantifier (* or + or ?), here * means "zero or more"
                ,*
            ]
            // `=>` - "expands to"
            =>
            // `{` opens the macro body
            {
                // ` $()*` Repetition Group, everything inside repeats for each captured field
            $(
                // `{}` - Scope Block - prevents variable name collisions, isolates each test case
                {
                    let mut args = Args::default();
                    // Metavariable substitution
                    args.$field = Some(0);
                    assert!(AppConfig::build(Some(args)).is_err(),
                           "{} should not accept 0", stringify!($field));
                }
            )*
        };
    }
        // because macro was defined as `[]`, but not `()`
        test_zero_fields![
            max_batch_size,
            max_wait_time_ms,
            batch_check_interval_ms,
            inference_timeout_secs,
            max_inference_inputs
        ];
    }
}
